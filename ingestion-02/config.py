#config.py

EMBEDDING_DIM = 512

FAISS_INDEX_DIR = "./vector_indexes"
DATASET_DIR = "./raw-datasets-01"

TEXT_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
IMAGE_MODEL_NAME = "openai/clip-vit-base-patch32"
